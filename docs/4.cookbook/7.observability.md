---
title: "Observability & Tracing"
description: "Setting up distributed tracing, metrics, and monitoring for pipelines"
author: zoobzio
published: 2025-12-26
updated: 2025-12-26
tags:
  - cookbook
  - observability
  - tracing
  - metrics
  - monitoring
  - signals
---

# Observability & Tracing

This recipe demonstrates how to set up comprehensive observability for your pipelines using the `Pipeline` wrapper, signals, and schema introspection.

## The Problem

You have a complex data processing pipeline and need:
- Distributed tracing across pipeline executions
- Metrics collection (latency, error rates, throughput)
- Real-time monitoring of circuit breakers and rate limiters
- Correlation of logs and events to specific executions

## The Solution

Combine three pipz features:
1. **Pipeline** - Injects execution and pipeline IDs into context
2. **Signals** - Connectors emit events at decision points
3. **Schema** - Introspect pipeline structure at build time

## Complete Example

```go
package main

import (
    "context"
    "log"
    "time"

    "github.com/zoobzio/capitan"
    "github.com/zoobzio/pipz"
)

// Define identities
var (
    OrderPipelineID = pipz.NewIdentity("order-pipeline", "Main order processing")
    ValidateID      = pipz.NewIdentity("validate", "Validates order data")
    EnrichID        = pipz.NewIdentity("enrich", "Enriches with customer data")
    SaveID          = pipz.NewIdentity("save", "Persists to database")
    APIBreakerID    = pipz.NewIdentity("api-breaker", "Protects external API")
    InternalSeqID   = pipz.NewIdentity("order-steps", "Processing sequence")
)

func main() {
    // Set up signal handlers BEFORE creating pipelines
    setupObservability()

    // Build the pipeline with tracing
    pipeline := buildOrderPipeline()

    // Log the pipeline structure
    logSchema(pipeline)

    // Process orders - each call gets unique execution ID
    for i := 0; i < 3; i++ {
        ctx := context.Background()
        _, err := pipeline.Process(ctx, Order{ID: i})
        if err != nil {
            log.Printf("Order %d failed: %v", i, err)
        }
    }
}

func buildOrderPipeline() *pipz.Pipeline[Order] {
    // Build processing logic with circuit breaker
    sequence := pipz.NewSequence(InternalSeqID,
        pipz.Apply(ValidateID, validateOrder),
        pipz.NewCircuitBreaker(APIBreakerID,
            pipz.Apply(EnrichID, enrichOrder),
            3,              // Open after 3 failures
            10*time.Second, // Reset after 10s
        ),
        pipz.Apply(SaveID, saveOrder),
    )

    // Wrap with Pipeline for execution context
    return pipz.NewPipeline(OrderPipelineID, sequence)
}

func setupObservability() {
    // Hook into circuit breaker state changes
    capitan.Hook(pipz.SignalCircuitBreakerOpened, func(ctx context.Context, e *capitan.Event) {
        execID, _ := pipz.ExecutionIDFromContext(ctx)
        pipeID, _ := pipz.PipelineIDFromContext(ctx)
        name, _ := pipz.FieldName.From(e)

        log.Printf("[ALERT] Circuit OPENED: %s (pipeline=%s, exec=%s)",
            name, pipeID, execID)

        // Send to your alerting system
        // alerting.Send("circuit-opened", name, execID)
    })

    capitan.Hook(pipz.SignalCircuitBreakerClosed, func(ctx context.Context, e *capitan.Event) {
        name, _ := pipz.FieldName.From(e)
        log.Printf("[INFO] Circuit CLOSED: %s - service recovered", name)
    })

    // Hook into sequence completion for latency metrics
    capitan.Hook(pipz.SignalSequenceCompleted, func(ctx context.Context, e *capitan.Event) {
        execID, _ := pipz.ExecutionIDFromContext(ctx)
        name, _ := pipz.FieldName.From(e)
        duration, _ := pipz.FieldDuration.From(e)
        count, _ := pipz.FieldProcessorCount.From(e)

        log.Printf("[METRIC] Sequence completed: %s (%d steps in %.3fs) exec=%s",
            name, count, duration, execID)

        // Record to your metrics system
        // metrics.RecordLatency("sequence.duration", duration, "name", name)
    })

    // Hook into rate limiter for throughput monitoring
    capitan.Hook(pipz.SignalRateLimiterThrottled, func(ctx context.Context, e *capitan.Event) {
        name, _ := pipz.FieldName.From(e)
        waitTime, _ := pipz.FieldWaitTime.From(e)

        log.Printf("[WARN] Rate limited: %s (waited %.3fs)", name, waitTime)
    })

    capitan.Hook(pipz.SignalRateLimiterDropped, func(ctx context.Context, e *capitan.Event) {
        execID, _ := pipz.ExecutionIDFromContext(ctx)
        name, _ := pipz.FieldName.From(e)

        log.Printf("[WARN] Request dropped by rate limiter: %s exec=%s", name, execID)

        // Increment dropped request counter
        // metrics.Increment("ratelimiter.dropped", "name", name)
    })

    // Hook into retry for transient failure tracking
    capitan.Hook(pipz.SignalRetryExhausted, func(ctx context.Context, e *capitan.Event) {
        execID, _ := pipz.ExecutionIDFromContext(ctx)
        name, _ := pipz.FieldName.From(e)
        attempts, _ := pipz.FieldMaxAttempts.From(e)
        errMsg, _ := pipz.FieldError.From(e)

        log.Printf("[ERROR] Retry exhausted: %s after %d attempts (err=%s) exec=%s",
            name, attempts, errMsg, execID)
    })
}

func logSchema(pipeline *pipz.Pipeline[Order]) {
    schema := pipz.NewSchema(pipeline.Schema())

    log.Printf("Pipeline: %s", pipeline.Identity().Name())
    log.Printf("Total nodes: %d", schema.Count())

    // Find all circuit breakers
    breakers := schema.FindByType("circuitbreaker")
    for _, b := range breakers {
        log.Printf("  CircuitBreaker: %s", b.Identity.Name())
    }

    // Walk all nodes
    schema.Walk(func(node pipz.Node) {
        log.Printf("  [%s] %s", node.Type, node.Identity.Name())
    })
}

// Domain types and functions
type Order struct {
    ID int
}

func (o Order) Clone() Order { return o }

func validateOrder(_ context.Context, o Order) (Order, error) { return o, nil }
func enrichOrder(_ context.Context, o Order) (Order, error)   { return o, nil }
func saveOrder(_ context.Context, o Order) (Order, error)     { return o, nil }
```

## Key Patterns

### 1. Pipeline Wrapping for Correlation

Always wrap your top-level chainable with `Pipeline`:

```go
// The semantic identity for the entire flow
pipeline := pipz.NewPipeline(OrderPipelineID, sequence)
```

This ensures every signal emitted includes correlation context.

### 2. Extract IDs in Handlers

```go
capitan.Hook(pipz.SignalCircuitBreakerOpened, func(ctx context.Context, e *capitan.Event) {
    execID, _ := pipz.ExecutionIDFromContext(ctx)
    pipeID, _ := pipz.PipelineIDFromContext(ctx)
    // Now you can correlate this event to a specific execution
})
```

### 3. Extract Typed Fields

Use the typed field keys for safe extraction:

```go
name, ok := pipz.FieldName.From(e)           // string
failures, ok := pipz.FieldFailures.From(e)   // int
duration, ok := pipz.FieldDuration.From(e)   // float64 (seconds)
state, ok := pipz.FieldState.From(e)         // string
```

### 4. Schema Introspection

Build documentation or visualizations from schema:

```go
schema := pipz.NewSchema(pipeline.Schema())

// Find specific components
breakers := schema.FindByType("circuitbreaker")
sequences := schema.FindByType("sequence")

// Walk entire structure
schema.Walk(func(node pipz.Node) {
    fmt.Printf("%s: %s\n", node.Type, node.Identity.Name())
})
```

## Available Signals

| Signal | Emitted When | Key Fields |
|--------|--------------|------------|
| `SignalCircuitBreakerOpened` | Circuit opens | `name`, `failures`, `threshold` |
| `SignalCircuitBreakerClosed` | Circuit closes | `name`, `successes` |
| `SignalCircuitBreakerHalfOpen` | Circuit tests | `name` |
| `SignalCircuitBreakerRejected` | Request blocked | `name`, `state` |
| `SignalRateLimiterAllowed` | Request passes | `name`, `tokens` |
| `SignalRateLimiterThrottled` | Request delayed | `name`, `wait_time` |
| `SignalRateLimiterDropped` | Request dropped | `name` |
| `SignalRetryAttemptStart` | Attempt begins | `name`, `attempt` |
| `SignalRetryAttemptFail` | Attempt fails | `name`, `attempt`, `error` |
| `SignalRetryExhausted` | All attempts fail | `name`, `max_attempts`, `error` |
| `SignalSequenceCompleted` | Sequence finishes | `name`, `processor_count`, `duration` |
| `SignalTimeoutTriggered` | Timeout expires | `name`, `duration` |
| `SignalWorkerPoolSaturated` | Pool at capacity | `name`, `worker_count` |

## Integration with External Systems

### OpenTelemetry

```go
capitan.Hook(pipz.SignalSequenceCompleted, func(ctx context.Context, e *capitan.Event) {
    execID, _ := pipz.ExecutionIDFromContext(ctx)
    duration, _ := pipz.FieldDuration.From(e)
    name, _ := pipz.FieldName.From(e)

    span := trace.SpanFromContext(ctx)
    span.SetAttributes(
        attribute.String("pipz.execution_id", execID.String()),
        attribute.String("pipz.sequence", name),
        attribute.Float64("pipz.duration_s", duration),
    )
})
```

### Prometheus

```go
var (
    sequenceLatency = prometheus.NewHistogramVec(
        prometheus.HistogramOpts{
            Name: "pipz_sequence_duration_seconds",
            Help: "Sequence execution duration",
        },
        []string{"sequence"},
    )
)

capitan.Hook(pipz.SignalSequenceCompleted, func(ctx context.Context, e *capitan.Event) {
    name, _ := pipz.FieldName.From(e)
    duration, _ := pipz.FieldDuration.From(e)
    sequenceLatency.WithLabelValues(name).Observe(duration)
})
```

## Best Practices

1. **Set up hooks before creating pipelines** - Ensures no events are missed
2. **Use Pipeline for all production flows** - Correlation IDs are essential for debugging
3. **Log execution IDs on errors** - Makes trace correlation trivial
4. **Monitor circuit breaker state** - Early warning of service degradation
5. **Track rate limiter drops** - Indicates capacity issues
6. **Schema at startup** - Log pipeline structure for debugging

## See Also

- [Pipeline Reference](../5.reference/4.connectors/pipeline.md)
- [Hooks Documentation](../2.learn/5.hooks.md)
- [Circuit Breaker Reference](../5.reference/4.connectors/circuitbreaker.md)
