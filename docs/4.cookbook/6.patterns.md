---
title: "Common Patterns"
description: "Powerful patterns built with pipz leveraging the Chainable interface and processor composition"
author: zoobzio
published: 2025-12-13
updated: 2025-12-13
tags:
  - cookbook
  - patterns
  - composition
  - architecture
  - best-practices
---

# Common Patterns

This guide demonstrates powerful patterns you can build with pipz by leveraging the `Chainable[T]` interface and composing processors.

## Complex Pipeline Architecture

Here's how a production-ready pipeline architecture looks when combining multiple patterns:

```
┌──────────────────────────────────────────────────────────────────┐
│              Production Order Processing Pipeline                 │
└──────────────────────────────────────────────────────────────────┘

                ┌─────────────────┐
                │   User Request  │
                └────────┬────────┘
                         │
                         ▼
                ┌─────────────────┐
                │  Rate Limiter   │──→ [Drop if exceeded]
                │  100 req/sec    │
                └────────┬────────┘
                         │
                         ▼
                ┌─────────────────┐
                │    Validate     │──→ [Fail fast on bad input]
                │  • Required     │
                │  • Business     │
                └────────┬────────┘
                         │
                         ▼
              ┌──────────┴──────────┐
              │   Switch Router     │
              │  (by order type)    │
              └─┬────────────────┬──┘
                │                │
        [premium user]     [regular user]
                │                │
         ┌──────▼──────┐  ┌──────▼──────┐
         │  Fast Path  │  │ Normal Path │
         │ • Priority  │  │ • Standard  │
         │ • Express   │  │ • Queue     │
         └──────┬──────┘  └──────┬──────┘
                │                │
                └────────┬───────┘
                         │
                         ▼
         ┌───────────────────────────────┐
         │     Circuit Breaker           │
         │   (Payment Processing)        │
         │  • Closed: Process normally   │
         │  • Open: Fail fast            │
         │  • Half-Open: Test recovery   │
         └───────────────┬───────────────┘
                         │
                         ▼
         ┌───────────────────────────────┐
         │    Retry with Backoff         │
         │  • Attempt 1: 100ms delay     │
         │  • Attempt 2: 200ms delay     │
         │  • Attempt 3: 400ms delay     │
         └───────────────┬───────────────┘
                         │
                         ▼
         ┌───────────────────────────────┐
         │      Timeout Wrapper          │
         │     (30 second limit)         │
         └───────────────┬───────────────┘
                         │
                    [Success]
                         │
                         ▼
         ┌───────────────────────────────┐
         │    Concurrent Notifications   │
         ├───────────────────────────────┤
         │ ┌─────────┐ ┌─────────┐      │
         │ │  Email  │ │   SMS   │      │
         │ └─────────┘ └─────────┘      │
         │ ┌─────────┐ ┌─────────┐      │
         │ │Analytics│ │   CRM   │      │
         │ └─────────┘ └─────────┘      │
         └───────────────────────────────┘
                         │
                    All complete
                         │
                         ▼
                ┌─────────────────┐
                │     Response     │
                └─────────────────┘

Error Flow:
═══════════
Any Stage [✗] ──→ Error Handler ──→ Categorize ──→ Recovery Strategy
                         │                              │
                         ▼                              ▼
                  [Log & Metrics]            [Retry / Fallback / Alert]
```

### Implementation of Complex Pipeline

```go
// Define order pipeline identities upfront
var (
    RateLimitID         = pipz.NewIdentity("rate-limit", "Rate limits incoming orders to 100/sec")
    ValidationID        = pipz.NewIdentity("validation", "Validates order requirements and business rules")
    ValidateRequiredID  = pipz.NewIdentity("validate-required", "Validates required order fields")
    ValidateBusinessID  = pipz.NewIdentity("validate-business", "Validates business logic rules")
    OrderRouterID       = pipz.NewIdentity("order-router", "Routes orders to premium or regular processing")
    FastPathID          = pipz.NewIdentity("fast-path", "Fast path for premium customers")
    PriorityQueueID     = pipz.NewIdentity("priority-queue", "Adds order to priority queue")
    ExpressProcessingID = pipz.NewIdentity("express-processing", "Processes order with express handling")
    NormalPathID        = pipz.NewIdentity("normal-path", "Standard path for regular customers")
    StandardQueueID     = pipz.NewIdentity("standard-queue", "Adds order to standard queue")
    StandardProcessingID = pipz.NewIdentity("standard-processing", "Processes order with standard handling")
    PaymentBreakerID    = pipz.NewIdentity("payment-breaker", "Circuit breaker for payment processing")
    PaymentRetryID      = pipz.NewIdentity("payment-retry", "Retries payment with exponential backoff")
    PaymentTimeoutID    = pipz.NewIdentity("payment-timeout", "Enforces 30 second timeout on payment")
    ChargePaymentID     = pipz.NewIdentity("charge-payment", "Charges customer payment method")
    NotificationsID     = pipz.NewIdentity("notifications", "Sends notifications in parallel")
    SendEmailID         = pipz.NewIdentity("send-email", "Sends email notification")
    SendSMSID           = pipz.NewIdentity("send-sms", "Sends SMS notification")
    UpdateAnalyticsID   = pipz.NewIdentity("update-analytics", "Updates analytics platform")
    UpdateCRMID         = pipz.NewIdentity("update-crm", "Updates CRM system")
    OrderPipelineID     = pipz.NewIdentity("order-pipeline", "Complete order processing pipeline")
)

// Build the complete pipeline shown in the diagram
func BuildOrderPipeline() pipz.Chainable[Order] {
    // Rate limiting layer
    rateLimiter := pipz.NewRateLimiter(RateLimitID, 100, 10)

    // Validation layer
    validation := pipz.NewSequence(ValidationID,
        pipz.Apply(ValidateRequiredID, validateRequired),
        pipz.Apply(ValidateBusinessID, validateBusinessRules),
    )
    
    // Routing layer - different paths for different users
    routing := pipz.NewSwitch(OrderRouterID,
        func(ctx context.Context, order Order) string {
            if order.Customer.IsPremium {
                return "premium"
            }
            return "regular"
        },
    ).
    AddRoute("premium", pipz.NewSequence(FastPathID,
        pipz.Apply(PriorityQueueID, addToPriorityQueue),
        pipz.Apply(ExpressProcessingID, expressProcess),
    )).
    AddRoute("regular", pipz.NewSequence(NormalPathID,
        pipz.Apply(StandardQueueID, addToStandardQueue),
        pipz.Apply(StandardProcessingID, standardProcess),
    ))

    // Payment processing with full resilience
    payment := pipz.NewCircuitBreaker(PaymentBreakerID,
        pipz.NewBackoff(PaymentRetryID,
            pipz.NewTimeout(PaymentTimeoutID,
                pipz.Apply(ChargePaymentID, chargePayment),
                30*time.Second,
            ),
            3,
            100*time.Millisecond,
        ),
        5,
        time.Minute,
    )

    // Concurrent notifications
    notifications := pipz.NewConcurrent(NotificationsID,
        pipz.Effect(SendEmailID, sendEmailNotification),
        pipz.Effect(SendSMSID, sendSMSNotification),
        pipz.Effect(UpdateAnalyticsID, updateAnalytics),
        pipz.Effect(UpdateCRMID, updateCRM),
    )

    // Compose everything
    return pipz.NewSequence(OrderPipelineID,
        rateLimiter,
        validation,
        routing,
        payment,
        notifications,
    )
}
```

## Infrastructure Patterns

### Rate Limiter (Built-in Connector)

Control the rate of processing to protect downstream services. pipz provides a built-in RateLimiter connector:

```go
// Define rate limiter identities
var (
    APIRateLimitID = pipz.NewIdentity("api-rate-limit", "Limits API calls to 100/sec with burst of 10")
    ThrottledAPIID = pipz.NewIdentity("throttled-api", "Rate-limited API call pipeline")
    CallAPIID      = pipz.NewIdentity("call-api", "Calls external API")
)

// 100 requests per second with burst of 10
rateLimiter := pipz.NewRateLimiter(APIRateLimitID, 100, 10)

// Configure mode: "wait" (default) or "drop"
rateLimiter.SetMode("drop") // Return error immediately if rate exceeded

// Use in a pipeline
pipeline := pipz.NewSequence(ThrottledAPIID,
    rateLimiter,
    pipz.Apply(CallAPIID, callExternalAPI),
)

// Runtime configuration
rateLimiter.SetRate(200)    // Update to 200/sec
rateLimiter.SetBurst(20)    // Update burst capacity
```

The RateLimiter uses a token bucket algorithm and provides:
- Two modes: "wait" (blocks until allowed) or "drop" (fails immediately)
- Runtime reconfiguration of rate and burst
- Context-aware cancellation during waits
- Thread-safe operation

### Circuit Breaker (Built-in Connector)

Prevent cascading failures by stopping requests to failing services. pipz provides a built-in CircuitBreaker connector:

```go
// Define circuit breaker identities
var (
    APIBreakerID    = pipz.NewIdentity("api-breaker", "Circuit breaker protecting API calls")
    ResilientAPIID  = pipz.NewIdentity("resilient-api", "Resilient API with circuit breaker and retry")
    RetryAPIID      = pipz.NewIdentity("retry-api", "Retries failed API calls")
    CallAPIBreakerID = pipz.NewIdentity("call-api", "Calls external API")
)

// Open circuit after 5 failures, try recovery after 30 seconds
breaker := pipz.NewCircuitBreaker(APIBreakerID, apiProcessor, 5, 30*time.Second)

// Configure thresholds
breaker.SetFailureThreshold(10)     // Failures to open
breaker.SetSuccessThreshold(3)      // Successes to close from half-open
breaker.SetResetTimeout(time.Minute) // Recovery timeout

// Check state
state := breaker.GetState() // "closed", "open", or "half-open"

// Manual reset if needed
breaker.Reset()

// Combine with retry for resilient API calls
resilientAPI := pipz.NewSequence(ResilientAPIID,
    breaker,
    pipz.NewRetry(RetryAPIID,
        pipz.Apply(CallAPIBreakerID, callAPI),
        3,
    ),
)
```

The CircuitBreaker implements the standard circuit breaker pattern with:
- Three states: closed (normal), open (blocking), half-open (testing)
- Automatic recovery attempts after timeout
- Configurable failure and success thresholds
- Thread-safe state management
- Manual reset capability

### Bulkhead Pattern

Isolate resources to prevent total system failure:

```go
type Bulkhead[T any] struct {
    identity  pipz.Identity
    semaphore chan struct{}
}

func NewBulkhead[T any](id pipz.Identity, maxConcurrent int) *Bulkhead[T] {
    return &Bulkhead[T]{
        identity:  id,
        semaphore: make(chan struct{}, maxConcurrent),
    }
}

func (b *Bulkhead[T]) Process(ctx context.Context, data T) (T, error) {
    select {
    case b.semaphore <- struct{}{}:
        defer func() { <-b.semaphore }()
        return data, nil
    case <-ctx.Done():
        return data, fmt.Errorf("bulkhead timeout: %w", ctx.Err())
    }
}

func (b *Bulkhead[T]) Identity() pipz.Identity { return b.identity }
func (b *Bulkhead[T]) Schema() pipz.Node       { return pipz.Node{Identity: b.identity, Type: "bulkhead"} }
func (b *Bulkhead[T]) Close() error            { return nil }

// Define bulkhead identities
var (
    DBOpsID        = pipz.NewIdentity("db-ops", "Database operations with bulkhead protection")
    DBBulkheadID   = pipz.NewIdentity("db-bulkhead", "Limits concurrent database connections")
    ExecuteQueryID = pipz.NewIdentity("execute-query", "Executes database query")
)

// Limit concurrent database connections
dbPipeline := pipz.NewSequence(DBOpsID,
    NewBulkhead[Query](DBBulkheadID, 10), // Max 10 concurrent
    pipz.Apply(ExecuteQueryID, executeQuery),
)
```

### Cache-Aside Pattern

Speed up processing with caching:

```go
type CacheAside[T any, K comparable] struct {
    identity pipz.Identity
    cache    sync.Map
    keyFunc  func(T) K
    ttl      time.Duration
    fallback pipz.Chainable[T]
}

type cacheEntry[T any] struct {
    value     T
    expiresAt time.Time
}

func (c *CacheAside[T, K]) Process(ctx context.Context, data T) (T, error) {
    key := c.keyFunc(data)

    // Check cache
    if cached, ok := c.cache.Load(key); ok {
        entry := cached.(cacheEntry[T])
        if time.Now().Before(entry.expiresAt) {
            return entry.value, nil
        }
        c.cache.Delete(key)
    }

    // Cache miss - use fallback
    result, err := c.fallback.Process(ctx, data)
    if err != nil {
        return data, err
    }

    // Cache the result
    c.cache.Store(key, cacheEntry[T]{
        value:     result,
        expiresAt: time.Now().Add(c.ttl),
    })

    return result, nil
}

func (c *CacheAside[T, K]) Identity() pipz.Identity { return c.identity }
func (c *CacheAside[T, K]) Schema() pipz.Node       { return pipz.Node{Identity: c.identity, Type: "cache-aside"} }
func (c *CacheAside[T, K]) Close() error            { return nil }

// Define cache-aside identities
var (
    UserLookupID = pipz.NewIdentity("user-lookup", "User lookup with cache-aside pattern")
    UserCacheID  = pipz.NewIdentity("user-cache", "Caches user lookups")
    FetchUserID  = pipz.NewIdentity("fetch-user", "Fetches user from database")
)

// Cache user lookups
userPipeline := pipz.NewSequence(UserLookupID,
    &CacheAside[UserRequest, string]{
        identity: UserCacheID,
        keyFunc:  func(r UserRequest) string { return r.UserID },
        ttl:      5 * time.Minute,
        fallback: pipz.Apply(FetchUserID, fetchUserFromDB),
    },
)
```

## Processing Patterns

### Validation Chain

Build complex validation from simple rules:

```go
// Define validation chain identities
var (
    RequiredFieldsValidationID = pipz.NewIdentity("required-fields", "Validates required order fields")
    BusinessRulesValidationID  = pipz.NewIdentity("business-rules", "Validates business rules")
    InventoryCheckID           = pipz.NewIdentity("inventory", "Checks inventory and marks backorders")
    OrderValidationChainID     = pipz.NewIdentity("order-validation", "Validates order through multiple checks")
)

// Each validator is a simple Effect processor
requiredFields := pipz.Effect(RequiredFieldsValidationID, func(ctx context.Context, order Order) error {
    if order.CustomerID == "" {
        return errors.New("customer ID required")
    }
    if len(order.Items) == 0 {
        return errors.New("order must have items")
    }
    return nil
})

businessRules := pipz.Effect(BusinessRulesValidationID, func(ctx context.Context, order Order) error {
    if order.Total > 10000 && !order.IsApproved {
        return errors.New("high-value orders require approval")
    }
    return nil
})

inventoryCheck := pipz.Apply(InventoryCheckID, func(ctx context.Context, order Order) (Order, error) {
    for i, item := range order.Items {
        available, err := checkInventory(ctx, item.SKU)
        if err != nil {
            return order, err
        }
        if available < item.Quantity {
            order.Items[i].Status = "backorder"
        }
    }
    return order, nil
})

// Compose into validation pipeline
validation := pipz.NewSequence(OrderValidationChainID,
    requiredFields,
    businessRules,
    inventoryCheck,
)
```

### Enrichment Pipeline

Add data from multiple sources without blocking on failures:

```go
// Define enrichment identities
var (
    RequiredEnrichmentID  = pipz.NewIdentity("required-enrichment", "Required data enrichment")
    CustomerDataID        = pipz.NewIdentity("customer-data", "Enriches with customer data")
    PricingID             = pipz.NewIdentity("pricing", "Calculates pricing")
    OptionalEnrichmentID  = pipz.NewIdentity("optional-enrichment", "Optional parallel enrichment")
    RecommendationsID     = pipz.NewIdentity("recommendations", "Adds product recommendations")
    LoyaltyPointsID       = pipz.NewIdentity("loyalty-points", "Calculates loyalty points")
    ShippingOptionsID     = pipz.NewIdentity("shipping-options", "Gets available shipping options")
    FullEnrichmentID      = pipz.NewIdentity("full-enrichment", "Complete enrichment pipeline")
)

// Core enrichment that must succeed
mustEnrich := pipz.NewSequence(RequiredEnrichmentID,
    pipz.Apply(CustomerDataID, enrichCustomerData),
    pipz.Apply(PricingID, calculatePricing),
)

// Optional enrichments that won't fail the pipeline
optionalEnrich := pipz.NewConcurrent(OptionalEnrichmentID,
    pipz.Enrich(RecommendationsID, addRecommendations),
    pipz.Enrich(LoyaltyPointsID, calculateLoyaltyPoints),
    pipz.Enrich(ShippingOptionsID, getShippingOptions),
)

// Combine required and optional
enrichmentPipeline := pipz.NewSequence(FullEnrichmentID,
    mustEnrich,
    optionalEnrich,
)
```

### Fan-out/Fan-in

Process data through multiple paths and aggregate results:

```go
// Define fan-out/fan-in identities
var (
    AnalyzeAllID      = pipz.NewIdentity("analyze-all", "Runs all text analyses in parallel")
    SentimentID       = pipz.NewIdentity("sentiment", "Analyzes text sentiment")
    KeywordsID        = pipz.NewIdentity("keywords", "Extracts keywords")
    LanguageID        = pipz.NewIdentity("language", "Detects language")
    AggregateResultsID = pipz.NewIdentity("aggregate", "Aggregates analysis results")
    TextAnalyticsID   = pipz.NewIdentity("text-analytics", "Complete text analytics pipeline")
)

// Fan-out to multiple processors
analysisResults := pipz.NewConcurrent(AnalyzeAllID,
    pipz.Transform(SentimentID, analyzeSentiment),
    pipz.Transform(KeywordsID, extractKeywords),
    pipz.Transform(LanguageID, detectLanguage),
)

// Fan-in with aggregation
aggregate := pipz.Transform(AggregateResultsID, func(ctx context.Context, results AnalysisResult) AnalysisResult {
    // Results from all three analyses are in the struct
    results.Score = (results.SentimentScore + results.KeywordRelevance) / 2
    return results
})

// Complete fan-out/fan-in pattern
analytics := pipz.NewSequence(TextAnalyticsID,
    analysisResults,
    aggregate,
)
```

### Conditional Processing Flows

Route processing based on data characteristics:

```go
// Define conditional processing identities
var (
    TypeRouterID          = pipz.NewIdentity("type-router", "Routes messages by type")
    PriorityRouterFlowID  = pipz.NewIdentity("priority-router", "Routes orders by priority")
    PremiumOnlyFilterID   = pipz.NewIdentity("premium-only", "Enables premium features for subscribers")
    PremiumFeaturesID     = pipz.NewIdentity("premium-features", "Premium user features")
    AdvancedAnalyticsID   = pipz.NewIdentity("advanced-analytics", "Runs advanced analytics")
    PrioritySupportID     = pipz.NewIdentity("priority-support", "Notifies priority support")
)

// Route by data type
typeRouter := pipz.NewSwitch(TypeRouterID,
    func(ctx context.Context, msg Message) string {
        return msg.Type
    },
).
    AddRoute("email", processEmail).
    AddRoute("sms", processSMS).
    AddRoute("push", processPushNotification)

// Route by business rules
priorityRouter := pipz.NewSwitch(PriorityRouterFlowID,
    func(ctx context.Context, order Order) string {
        if order.Total > 1000 || order.IsPriority {
            return "express"
        }
        return "standard"
    },
).
    AddRoute("express", expressProcessing).
    AddRoute("standard", standardProcessing)

// Conditional execution
premiumFeatures := pipz.NewFilter(PremiumOnlyFilterID,
    func(ctx context.Context, user User) bool {
        return user.Subscription == "premium"
    },
    pipz.NewSequence(PremiumFeaturesID,
        pipz.Apply(AdvancedAnalyticsID, runAdvancedAnalytics),
        pipz.Apply(PrioritySupportID, notifyPrioritySupport),
    ),
)
```

## Integration Patterns

### API Gateway Pattern

Build a complete API gateway with pipz:

```go
// Define API gateway identities
var (
    APIGatewayID       = pipz.NewIdentity("api-gateway", "Complete API gateway with auth, validation, and routing")
    ClientRateLimitID  = pipz.NewIdentity("client-rate-limit", "Limits client requests to 100/sec")
    AuthenticateID     = pipz.NewIdentity("authenticate", "Authenticates API request")
    AuthorizeID        = pipz.NewIdentity("authorize", "Checks user permissions")
    ValidateGatewayID  = pipz.NewIdentity("validate", "Validates request payload")
    BackendBreakerID   = pipz.NewIdentity("backend-breaker", "Circuit breaker for backend services")
    RouteBackendID     = pipz.NewIdentity("route", "Routes to backend service")
    DeadlineID         = pipz.NewIdentity("deadline", "Enforces 30 second deadline")
    FormatResponseID   = pipz.NewIdentity("format-response", "Formats API response")
    GatewayRecoveryID  = pipz.NewIdentity("gateway", "API gateway with error recovery")
    ErrorHandlerGWID   = pipz.NewIdentity("error-handler", "Handles and formats API errors")
    FormatErrorID      = pipz.NewIdentity("format-error", "Formats error response")
    LogErrorID         = pipz.NewIdentity("log-error", "Logs error details")
    RecordMetricsID    = pipz.NewIdentity("metrics", "Records error metrics")
)

// API Gateway pipeline using built-in connectors
apiGateway := pipz.NewSequence(APIGatewayID,
    // Rate limiting per client
    pipz.NewRateLimiter(ClientRateLimitID, 100, 20), // 100/sec, burst 20

    // Authentication
    pipz.Apply(AuthenticateID, authenticateRequest),

    // Authorization
    pipz.Apply(AuthorizeID, checkPermissions),

    // Request validation
    pipz.Apply(ValidateGatewayID, validateRequest),

    // Circuit breaker for backend
    pipz.NewCircuitBreaker(BackendBreakerID,
        pipz.NewSwitch(RouteBackendID,
            routeToBackend).
            AddRoute("users", userService).
            AddRoute("orders", orderService).
            AddRoute("products", productService),
        10,              // Open after 10 failures
        time.Minute,     // Try recovery after 1 minute
    ),

    // Timeout wrapper
    pipz.NewTimeout(DeadlineID,
        pipz.Transform(FormatResponseID, formatResponse),
        30*time.Second,
    ),
)

// With error handling
gatewayWithRecovery := pipz.NewHandle(GatewayRecoveryID,
    apiGateway,
    pipz.NewSequence(ErrorHandlerGWID,
        pipz.Transform(FormatErrorID, formatErrorResponse),
        pipz.Effect(LogErrorID, logError),
        pipz.Effect(RecordMetricsID, recordErrorMetrics),
    ),
)
```


### Message Queue Integration

Process messages from queues reliably:

```go
type QueueProcessor[T any] struct {
    name     string
    queue    MessageQueue
    pipeline pipz.Chainable[T]
    decoder  func([]byte) (T, error)
}

func (qp *QueueProcessor[T]) Run(ctx context.Context) error {
    for {
        select {
        case <-ctx.Done():
            return ctx.Err()
        default:
            msg, err := qp.queue.Receive(ctx)
            if err != nil {
                continue
            }
            
            data, err := qp.decoder(msg.Body)
            if err != nil {
                msg.Nack()
                continue
            }
            
            _, err = qp.pipeline.Process(ctx, data)
            if err != nil {
                // Check if error is retryable
                var pipeErr *pipz.Error[T]
                if errors.As(err, &pipeErr) && pipeErr.Timeout {
                    msg.Requeue()
                } else {
                    msg.Nack()
                }
                continue
            }
            
            msg.Ack()
        }
    }
}

var (
    ProcessOrderQueueID   = pipz.NewIdentity("process-order", "Processes order from message queue")
    ProcessWithRetryID    = pipz.NewIdentity("process-with-retry", "Retries failed order processing")
    TimeoutWrapperID      = pipz.NewIdentity("timeout-wrapper", "Enforces 30 second timeout")
)

// Create a resilient message processor
messageProcessor := &QueueProcessor[Order]{
    name:    "order-queue",
    queue:   orderQueue,
    decoder: decodeOrderMessage,
    pipeline: pipz.NewSequence(ProcessOrderQueueID,
        pipz.NewRetry(ProcessWithRetryID,
            pipz.NewTimeout(TimeoutWrapperID,
                orderProcessingPipeline,
                30*time.Second,
            ),
            3,
        ),
    ),
}
```

## Performance Patterns

### Batch Processing

Process items in batches for efficiency:

```go
type Batcher[T any] struct {
    identity  pipz.Identity
    batchSize int
    timeout   time.Duration
    processor pipz.Chainable[[]T]

    mu    sync.Mutex
    batch []T
    timer *time.Timer
}

func (b *Batcher[T]) Process(ctx context.Context, item T) (T, error) {
    b.mu.Lock()
    b.batch = append(b.batch, item)

    if len(b.batch) >= b.batchSize {
        batch := b.batch
        b.batch = nil
        b.mu.Unlock()

        _, err := b.processor.Process(ctx, batch)
        return item, err
    }

    if b.timer == nil {
        b.timer = time.AfterFunc(b.timeout, func() {
            b.flush(context.Background())
        })
    }

    b.mu.Unlock()
    return item, nil
}

func (b *Batcher[T]) Identity() pipz.Identity { return b.identity }
func (b *Batcher[T]) Schema() pipz.Node       { return pipz.Node{Identity: b.identity, Type: "batcher"} }
func (b *Batcher[T]) Close() error            { return nil }

var (
    BatchLogsID  = pipz.NewIdentity("batch-logs", "Batches log entries for bulk insert")
    BulkInsertID = pipz.NewIdentity("bulk-insert", "Bulk inserts log entries")
)

// Batch database inserts
batchInsert := &Batcher[LogEntry]{
    identity:  BatchLogsID,
    batchSize: 100,
    timeout:   time.Second,
    processor: pipz.Apply(BulkInsertID, bulkInsertLogs),
}
```

### Async Fire-and-Forget

Process without waiting for completion:

```go
type AsyncProcessor[T any] struct {
    identity  pipz.Identity
    processor pipz.Chainable[T]
    buffer    chan T
}

func NewAsyncProcessor[T any](id pipz.Identity, proc pipz.Chainable[T], bufferSize int) *AsyncProcessor[T] {
    ap := &AsyncProcessor[T]{
        identity:  id,
        processor: proc,
        buffer:    make(chan T, bufferSize),
    }

    // Start background processor
    go func() {
        for item := range ap.buffer {
            ctx, cancel := context.WithTimeout(context.Background(), time.Minute)
            ap.processor.Process(ctx, item)
            cancel()
        }
    }()

    return ap
}

func (ap *AsyncProcessor[T]) Process(ctx context.Context, data T) (T, error) {
    select {
    case ap.buffer <- data:
        return data, nil
    case <-ctx.Done():
        return data, fmt.Errorf("async buffer full")
    }
}

func (ap *AsyncProcessor[T]) Identity() pipz.Identity { return ap.identity }
func (ap *AsyncProcessor[T]) Schema() pipz.Node       { return pipz.Node{Identity: ap.identity, Type: "async"} }
func (ap *AsyncProcessor[T]) Close() error            { close(ap.buffer); return nil }

var (
    AsyncAnalyticsID  = pipz.NewIdentity("async-analytics", "Async fire-and-forget analytics processor")
    AnalyticsID       = pipz.NewIdentity("analytics", "Analytics data processing pipeline")
    EnrichAnalyticsID = pipz.NewIdentity("enrich", "Enriches analytics data")
    SendAnalyticsID   = pipz.NewIdentity("send", "Sends to analytics platform")
)

// Fire-and-forget analytics
asyncAnalytics := NewAsyncProcessor(AsyncAnalyticsID,
    pipz.NewSequence(AnalyticsID,
        pipz.Apply(EnrichAnalyticsID, enrichAnalyticsData),
        pipz.Apply(SendAnalyticsID, sendToAnalytics),
    ),
    1000, // Buffer up to 1000 events
)
```

## Best Practices

1. **Keep it Simple**: Start with basic processors and compose them
2. **Name Everything**: Use descriptive names for debugging
3. **Test in Isolation**: Test each custom processor independently
4. **Monitor Performance**: Use benchmarks for critical paths
5. **Handle Context**: Always respect context cancellation
6. **Document Behavior**: Especially for complex custom processors

## Next Steps

- Review [performance guide](../3.guides/7.performance.md) for optimization tips
- Check [Safety and Reliability](../3.guides/8.safety-reliability.md) for resilience patterns