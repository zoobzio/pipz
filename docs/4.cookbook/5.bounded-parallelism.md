---
title: "Bounded Parallelism Patterns"
description: "Control resource usage with WorkerPool for predictable parallel processing"
author: zoobzio
published: 2025-12-13
updated: 2025-12-13
tags:
  - cookbook
  - parallelism
  - worker-pool
  - rate-limiting
  - concurrency
---

# Bounded Parallelism Patterns

Control resource usage with WorkerPool for predictable parallel processing.

## Problem

You need parallel processing but face constraints:
- External APIs have rate limits
- Database connection pools are limited
- Memory or CPU resources are constrained
- You need predictable resource usage
- Testing requires controlled concurrency

## Solution

Use `WorkerPool` to limit concurrent execution while maintaining parallelism benefits.

## Basic Pattern

```go
// Define identity upfront
var (
    LimitedID = pipz.NewIdentity("limited", "Limits concurrent operations to 5 workers")
)

// Limit to 5 concurrent operations
pool := pipz.NewWorkerPool[Data](LimitedID, 5,
    processor1,
    processor2,
    processor3,
    // ... can have many more processors
)
// Only 5 will run at any time
```

## Common Scenarios

### API Rate Limiting

**Problem:** External API allows only 10 concurrent connections.

```go
type APICall struct {
    Endpoint string
    UserID   string
    Data     map[string]interface{}
}

func (a APICall) Clone() APICall {
    data := make(map[string]interface{}, len(a.Data))
    for k, v := range a.Data {
        data[k] = v
    }
    return APICall{
        Endpoint: a.Endpoint,
        UserID:   a.UserID,
        Data:     data,
    }
}

// Define API pool identities
var (
    ExternalAPIID       = pipz.NewIdentity("external-api", "Worker pool limited to 10 concurrent API calls")
    UserDataID          = pipz.NewIdentity("user-data", "Fetches user data from API")
    PreferencesID       = pipz.NewIdentity("preferences", "Fetches user preferences")
    HistoryID           = pipz.NewIdentity("history", "Fetches user history")
    RecommendationsID   = pipz.NewIdentity("recommendations", "Fetches personalized recommendations")
    NotificationsID     = pipz.NewIdentity("notifications", "Fetches user notifications")
    UserEnrichmentID    = pipz.NewIdentity("user-enrichment", "Enriches user data from external API")
    ValidateRequestID   = pipz.NewIdentity("validate", "Validates API request")
    AggregateID         = pipz.NewIdentity("aggregate", "Aggregates API responses")
)

// Create pool respecting API limits
var apiPool = pipz.NewWorkerPool(ExternalAPIID, 10,
    pipz.Apply(UserDataID, fetchUserData),
    pipz.Apply(PreferencesID, fetchPreferences),
    pipz.Apply(HistoryID, fetchHistory),
    pipz.Apply(RecommendationsID, fetchRecommendations),
    pipz.Apply(NotificationsID, fetchNotifications),
).WithTimeout(30 * time.Second)

// Use in pipeline
pipeline := pipz.NewSequence[APICall](UserEnrichmentID,
    pipz.Apply(ValidateRequestID, validateRequest),
    apiPool, // Respects 10 connection limit
    pipz.Apply(AggregateID, aggregateResponses),
)
```

### Database Connection Management

**Problem:** Database allows only 25 connections, but you have hundreds of operations.

```go
type DBOperation struct {
    Query  string
    Params []interface{}
    Type   string // "read" or "write"
}

func (d DBOperation) Clone() DBOperation {
    params := make([]interface{}, len(d.Params))
    copy(params, d.Params)
    return DBOperation{
        Query:  d.Query,
        Params: params,
        Type:   d.Type,
    }
}

// Define database pool identities
var (
    DBReadID       = pipz.NewIdentity("db-read", "Read pool with 20 concurrent connections")
    FetchUsersID   = pipz.NewIdentity("fetch-users", "Fetches user records")
    FetchOrdersID  = pipz.NewIdentity("fetch-orders", "Fetches order records")
    FetchProductsID = pipz.NewIdentity("fetch-products", "Fetches product records")
    DBWriteID      = pipz.NewIdentity("db-write", "Write pool with 5 concurrent connections")
    UpdateUserID   = pipz.NewIdentity("update-user", "Updates user record")
    InsertOrderID  = pipz.NewIdentity("insert-order", "Inserts new order")
    LogEventID     = pipz.NewIdentity("log-event", "Logs database event")
    DBRouterID     = pipz.NewIdentity("db-router", "Routes database operations by type")
)

// Separate pools for read and write operations
var (
    readPool = pipz.NewWorkerPool(DBReadID, 20,
        pipz.Apply(FetchUsersID, fetchUsers),
        pipz.Apply(FetchOrdersID, fetchOrders),
        pipz.Apply(FetchProductsID, fetchProducts),
        // Many more read operations
    )

    writePool = pipz.NewWorkerPool(DBWriteID, 5,
        pipz.Apply(UpdateUserID, updateUser),
        pipz.Apply(InsertOrderID, insertOrder),
        pipz.Apply(LogEventID, logEvent),
        // Fewer write connections
    )
)

// Route based on operation type
dbRouter := pipz.NewSwitch[DBOperation](DBRouterID,
    func(ctx context.Context, op DBOperation) string {
        return op.Type
    },
).
AddRoute("read", readPool).
AddRoute("write", writePool)
```

### Memory-Constrained Processing

**Problem:** Image processing consumes significant memory; unlimited parallelism causes OOM.

```go
type ImageJob struct {
    SourcePath string
    TargetPath string
    Operations []string
}

func (i ImageJob) Clone() ImageJob {
    ops := make([]string, len(i.Operations))
    copy(ops, i.Operations)
    return ImageJob{
        SourcePath: i.SourcePath,
        TargetPath: i.TargetPath,
        Operations: ops,
    }
}

// Define image processing identities
var (
    ImageProcessingID = pipz.NewIdentity("image-processing", "Image processing pool with memory-based limits")
    ResizeID          = pipz.NewIdentity("resize", "Resizes image to target dimensions")
    CropID            = pipz.NewIdentity("crop", "Crops image to specified area")
    WatermarkID       = pipz.NewIdentity("watermark", "Adds watermark to image")
    OptimizeID        = pipz.NewIdentity("optimize", "Optimizes image size and quality")
)

// Limit based on available memory
// Assume each operation uses ~100MB
availableMemory := getAvailableMemory()
maxWorkers := availableMemory / (100 * 1024 * 1024) // 100MB per worker

imageProcessor := pipz.NewWorkerPool(ImageProcessingID, maxWorkers,
    pipz.Transform(ResizeID, resizeImage),
    pipz.Transform(CropID, cropImage),
    pipz.Transform(WatermarkID, addWatermark),
    pipz.Transform(OptimizeID, optimizeImage),
).WithTimeout(60 * time.Second)
```

### Multi-Service Orchestration

**Problem:** Calling multiple microservices with different rate limits.

```go
type ServiceCall struct {
    Service  string
    Method   string
    Payload  interface{}
    Priority int
}

func (s ServiceCall) Clone() ServiceCall {
    // Clone based on payload type
    return ServiceCall{
        Service:  s.Service,
        Method:   s.Method,
        Payload:  clonePayload(s.Payload),
        Priority: s.Priority,
    }
}

// Define service pool identities
var (
    CriticalID          = pipz.NewIdentity("critical", "Critical service pool with 20 workers")
    AuthID              = pipz.NewIdentity("auth", "Calls authentication service")
    PaymentServiceID    = pipz.NewIdentity("payment", "Calls payment service")
    InventoryServiceID  = pipz.NewIdentity("inventory", "Calls inventory service")
    StandardID          = pipz.NewIdentity("standard", "Standard service pool with 10 workers")
    RecommendationID    = pipz.NewIdentity("recommendations", "Calls recommendation service")
    AnalyticsServiceID  = pipz.NewIdentity("analytics", "Calls analytics service")
    NotificationID      = pipz.NewIdentity("notifications", "Calls notification service")
    BackgroundID        = pipz.NewIdentity("background", "Background service pool with 5 workers")
    ReportingID         = pipz.NewIdentity("reporting", "Calls reporting service")
    BackupID            = pipz.NewIdentity("backup", "Calls backup service")
    CleanupID           = pipz.NewIdentity("cleanup", "Calls cleanup service")
    ServiceRouterID     = pipz.NewIdentity("service-router", "Routes service calls by priority")
)

// Different limits per service tier
var (
    criticalServices = pipz.NewWorkerPool(CriticalID, 20,
        pipz.Apply(AuthID, callAuthService),
        pipz.Apply(PaymentServiceID, callPaymentService),
        pipz.Apply(InventoryServiceID, callInventoryService),
    )

    standardServices = pipz.NewWorkerPool(StandardID, 10,
        pipz.Apply(RecommendationID, callRecommendationService),
        pipz.Apply(AnalyticsServiceID, callAnalyticsService),
        pipz.Apply(NotificationID, callNotificationService),
    )

    backgroundServices = pipz.NewWorkerPool(BackgroundID, 5,
        pipz.Apply(ReportingID, callReportingService),
        pipz.Apply(BackupID, callBackupService),
        pipz.Apply(CleanupID, callCleanupService),
    )
)

// Route by priority
serviceRouter := pipz.NewSwitch[ServiceCall](ServiceRouterID,
    func(ctx context.Context, call ServiceCall) string {
        switch call.Priority {
        case 1:
            return "critical"
        case 2:
            return "standard"
        default:
            return "background"
        }
    },
).
AddRoute("critical", criticalServices).
AddRoute("standard", standardServices).
AddRoute("background", backgroundServices)
```

## Advanced Patterns

### Dynamic Worker Adjustment

Adjust worker count based on system load:

```go
type AdaptivePool struct {
    pool        *pipz.WorkerPool[Data]
    minWorkers  int
    maxWorkers  int
    adjustEvery time.Duration
}

func NewAdaptivePool(id *pipz.Identity, min, max int) *AdaptivePool {
    return &AdaptivePool{
        pool:        pipz.NewWorkerPool[Data](id, min),
        minWorkers:  min,
        maxWorkers:  max,
        adjustEvery: 30 * time.Second,
    }
}

func (a *AdaptivePool) Start(ctx context.Context) {
    ticker := time.NewTicker(a.adjustEvery)
    go func() {
        defer ticker.Stop()
        for {
            select {
            case <-ctx.Done():
                return
            case <-ticker.C:
                a.adjustWorkers()
            }
        }
    }()
}

func (a *AdaptivePool) adjustWorkers() {
    active := a.pool.GetActiveWorkers()
    current := a.pool.GetWorkerCount()
    
    utilization := float64(active) / float64(current)
    
    if utilization > 0.8 && current < a.maxWorkers {
        // Scale up
        newCount := min(current+5, a.maxWorkers)
        a.pool.SetWorkerCount(newCount)
        log.Printf("Scaled up to %d workers", newCount)
    } else if utilization < 0.3 && current > a.minWorkers {
        // Scale down
        newCount := max(current-5, a.minWorkers)
        a.pool.SetWorkerCount(newCount)
        log.Printf("Scaled down to %d workers", newCount)
    }
}
```

### Combining with Circuit Breaker

Protect services with both bounded parallelism and circuit breaking:

```go
// Define protected API identities
var (
    APIProtectionID = pipz.NewIdentity("api-protection", "Protects API with circuit breaker and worker pool")
    APILimitedID    = pipz.NewIdentity("api-limited", "Worker pool limited to 10 concurrent API calls")
    Endpoint1ID     = pipz.NewIdentity("endpoint-1", "Calls API endpoint 1")
    Endpoint2ID     = pipz.NewIdentity("endpoint-2", "Calls API endpoint 2")
    Endpoint3ID     = pipz.NewIdentity("endpoint-3", "Calls API endpoint 3")
)

// Limit connections AND protect from cascading failures
protectedAPI := pipz.NewCircuitBreaker(APIProtectionID,
    pipz.NewWorkerPool(APILimitedID, 10,
        pipz.Apply(Endpoint1ID, callEndpoint1),
        pipz.Apply(Endpoint2ID, callEndpoint2),
        pipz.Apply(Endpoint3ID, callEndpoint3),
    ).WithTimeout(5 * time.Second),
    pipz.WithCircuitBreakerThreshold(5),
    pipz.WithCircuitBreakerWindow(30 * time.Second),
)
```

### Priority Queue with Worker Pool

Process high-priority items first:

```go
type PriorityProcessor struct {
    highPriority   *pipz.WorkerPool[Task]
    normalPriority *pipz.WorkerPool[Task]
    lowPriority    *pipz.WorkerPool[Task]
}

func NewPriorityProcessor() *PriorityProcessor {
    return &PriorityProcessor{
        highPriority: pipz.NewWorkerPool[Task]("high", 10,
            // High priority processors
        ),
        normalPriority: pipz.NewWorkerPool[Task]("normal", 5,
            // Normal priority processors
        ),
        lowPriority: pipz.NewWorkerPool[Task]("low", 2,
            // Low priority processors
        ),
    }
}

func (p *PriorityProcessor) Process(ctx context.Context, task Task) (Task, error) {
    switch task.Priority {
    case "high":
        return p.highPriority.Process(ctx, task)
    case "normal":
        return p.normalPriority.Process(ctx, task)
    default:
        return p.lowPriority.Process(ctx, task)
    }
}
```

## Testing with Worker Pools

Control concurrency for deterministic tests:

```go
func TestConcurrentOperations(t *testing.T) {
    // Define test identities
    var (
        TestID = pipz.NewIdentity("test", "Test pool with single worker for deterministic testing")
        Op1ID  = pipz.NewIdentity("op1", "Test operation 1")
        Op2ID  = pipz.NewIdentity("op2", "Test operation 2")
        Op3ID  = pipz.NewIdentity("op3", "Test operation 3")
    )

    // Use single worker for deterministic behavior
    pool := pipz.NewWorkerPool[TestData](TestID, 1,
        pipz.Apply(Op1ID, operation1),
        pipz.Apply(Op2ID, operation2),
        pipz.Apply(Op3ID, operation3),
    )

    // Operations run sequentially despite being in pool
    result, err := pool.Process(context.Background(), testData)
    assert.NoError(t, err)
    assert.Equal(t, expected, result)
}

// Define benchmark identities
var (
    Bench1ID  = pipz.NewIdentity("bench-1", "Benchmark pool with 1 worker")
    Bench2ID  = pipz.NewIdentity("bench-2", "Benchmark pool with 2 workers")
    Bench4ID  = pipz.NewIdentity("bench-4", "Benchmark pool with 4 workers")
    Bench8ID  = pipz.NewIdentity("bench-8", "Benchmark pool with 8 workers")
    Bench16ID = pipz.NewIdentity("bench-16", "Benchmark pool with 16 workers")
)

func BenchmarkWorkerPoolScaling(b *testing.B) {
    benchIDs := map[int]*pipz.Identity{
        1:  Bench1ID,
        2:  Bench2ID,
        4:  Bench4ID,
        8:  Bench8ID,
        16: Bench16ID,
    }

    for workers := 1; workers <= 16; workers *= 2 {
        b.Run(fmt.Sprintf("workers-%d", workers), func(b *testing.B) {
            pool := pipz.NewWorkerPool[Data](benchIDs[workers], workers,
                // Add processors
            )

            b.ResetTimer()
            for i := 0; i < b.N; i++ {
                pool.Process(context.Background(), benchData)
            }
        })
    }
}
```

## Common Pitfalls

### ❌ Creating pools per request
```go
// Define anti-pattern identity (for demonstration)
var (
    PerRequestPoolID = pipz.NewIdentity("pool", "Per-request pool (anti-pattern)")
)

// WRONG - Defeats the purpose
func handleRequest(req Request) {
    pool := pipz.NewWorkerPool(PerRequestPoolID, 5, processors...)
    return pool.Process(ctx, req)
}
```

### ✅ Use singleton pools
```go
// Define shared pool identity
var (
    SharedPoolID = pipz.NewIdentity("pool", "Shared request processing pool")
)

// RIGHT - Shared pool
var pool = pipz.NewWorkerPool(SharedPoolID, 5, processors...)

func handleRequest(req Request) {
    return pool.Process(ctx, req)
}
```

### ❌ Too few workers
```go
// Define undersized pool identity (for demonstration)
var (
    TinyID = pipz.NewIdentity("tiny", "Undersized pool causing bottleneck")
)

// WRONG - Essentially sequential
pool := pipz.NewWorkerPool(TinyID, 1,
    proc1, proc2, proc3, proc4, proc5) // Bottleneck!
```

### ✅ Balance workers with workload
```go
// Define balanced pool identity
var (
    BalancedID = pipz.NewIdentity("balanced", "Well-balanced worker pool")
)

// RIGHT - Appropriate for workload
pool := pipz.NewWorkerPool(BalancedID, 10,
    proc1, proc2, proc3, proc4, proc5) // Good parallelism
```

## When to Use WorkerPool

✅ **Use WorkerPool when:**
- External services have connection limits
- Memory or CPU constraints exist
- You need predictable resource usage
- Testing requires controlled concurrency
- Database connection pools are limited

❌ **Don't use WorkerPool when:**
- You need maximum parallelism (use Concurrent)
- Operations must run sequentially (use Sequence)
- Fire-and-forget is needed (use Scaffold)
- You only have a few processors

## See Also

- [Concurrent](../5.reference/4.connectors/concurrent.md) - Unbounded parallelism
- [Scaffold](../5.reference/3.processors/scaffold.md) - Fire-and-forget execution
- [RateLimiter](../5.reference/4.connectors/ratelimiter.md) - Time-based rate limiting
- [Resilient API Calls](./1.resilient-api-calls.md) - Complete API resilience patterns